{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c43bbd-5d2f-45a7-9d6f-a9fc676b1e15",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bf3c892-f899-40e5-a3f6-fb55bf37f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rs = 1234\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4e73-6fc4-4585-b6c5-a4e2a9643b61",
   "metadata": {},
   "source": [
    "## Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ace1d630-1d0a-4718-be08-7f0fe2205b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbb74580-f713-4b62-ba27-452ce32d7614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should print type='cuda' if GPU is available, otherwise 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911c685-bff4-48f4-93fa-fa5afa20ce5e",
   "metadata": {},
   "source": [
    "## Defining the Auto-Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78f57b9f-3d54-403f-ba2f-8f3744a787a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder network. \n",
    "    A deep neural network that learns a lower-dimensional representation of the input data by mapping it into an embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                hidden_layers: Tuple[int],\n",
    "                 dropout_rate: float=0.2,\n",
    "                 activation=nn.ReLU()\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First layer, the input layer\n",
    "        self.input_layer = torch.nn.Linear(input_size, hidden_layers[0])\n",
    "        self.n_layers = 0\n",
    "\n",
    "        ######################################################\n",
    "        # Usually we could specify the layers in this way:\n",
    "        # self.dense_0 = torch.nn.Linear(input_size, hidden_layers[0])\n",
    "        # self.dense_1 = torch.nn.Linear(hidden_layers[0], hidden_layers[1])\n",
    "        # ....\n",
    "        # \n",
    "        # However, instead of hardcoding this, we can do it automatically based on the hidden_layers\n",
    "        # The output of one hidden_layer will always be the input for the next hidden_layet\n",
    "        #######################################################\n",
    "        for i in range(0, len(hidden_layers) -1):\n",
    "            setattr(self, f\"dense_{i}\", torch.nn.Linear(hidden_layers[i],\n",
    "                                                        hidden_layers[i+1])\n",
    "                   )\n",
    "            self.n_layers += 1\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.hidden_layers = hidden_layers\n",
    "        \n",
    "        # Add dropout to prevent overfitting\n",
    "        self.dropout  = nn.Dropout(dropout_rate)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # Special Treatment for input layer\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        #################################################\n",
    "        # forward pass through the dense layers\n",
    "        # We could have written each dense layer explicitly:\n",
    "        # x = self.activation(self.dense_0(x))\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.activation(self.dense_1(x))\n",
    "        # .....\n",
    "        # \n",
    "        # But we do it automatically:\n",
    "        ##################################################\n",
    "        for i in range(0, self.n_layers -1):\n",
    "            x = self.activation(getattr(self, f\"dense_{i}\")(x))\n",
    "            # dropout to prevent overfitting\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Use layer without activation function to output embedding\n",
    "        output_layer = getattr(self, f\"dense_{self.n_layers-1}\")\n",
    "        return output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9dedb01-4e68-425a-99b6-a486d3670a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Same as the encoder, but the layers are in reverse order. \n",
    "    So, we pass the encoder as input and use its hidden_sizes to specify the decoder network.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 activation=nn.ReLU()\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = encoder.hidden_layers\n",
    "        n_layers = encoder.n_layers\n",
    "        self.hidden_layers = self.hidden_layers[::-1]\n",
    "        \n",
    "        # Reversed order -> dense_0 will be the first to apply here\n",
    "        for i in range(0, n_layers):\n",
    "            setattr(self, f\"dense_{i}\", torch.nn.Linear(self.hidden_layers[i],\n",
    "                                                        self.hidden_layers[i+1])\n",
    "                   )\n",
    "        self.output_layer = torch.nn.Linear(self.hidden_layers[-1],\n",
    "                                                        encoder.input_size)\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "        self.dropout  = nn.Dropout(encoder.dropout_rate)\n",
    "\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        for i in range(0, self.n_layers):\n",
    "            dense_i = getattr(self, f\"dense_{i}\")\n",
    "            x = dense_i(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03bc9e67-81b1-42a5-9aa4-181b3eb5e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete AutoEncoder that consists of the encoder and the decoder network. \n",
    "    We need this for training, but for applying the autoencoder, we will only need the encoder to map input data to an embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                hidden_layers: Tuple[int],\n",
    "                 dropout_rate: float=0.2,\n",
    "                activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_layers, dropout_rate)\n",
    "        self.decoder = Decoder(self.encoder)\n",
    "        self.hidden_layers = hidden_layers\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor]:\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96218cd6-3757-4c7b-a5b4-bbfa306e4347",
   "metadata": {},
   "source": [
    "### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd5ab1a3-eb94-44e4-b941-37a4d0efe89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = MNIST('./', download=True,\n",
    "                 train=True,\n",
    "                 transform=transform)\n",
    "testset = MNIST('./', download=True,\n",
    "                 train=False,\n",
    "                 transform=transform)\n",
    "dataset = ConcatDataset([trainset, testset])\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=256, \n",
    "                                         shuffle=True,\n",
    "                                         num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e04b913a-ae78-46c0-95b3-6ed4fc451e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = trainset.data.numpy().reshape(60000, 784)\n",
    "X_test = testset.data.numpy().reshape(10000, 784)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d54bb60-0502-404b-855e-124bb3b115ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(trainset.targets)\n",
    "y_test = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e088416a-a7f7-4c8b-abd3-c09138017a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate([y_train, y_test])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62a55a-f9b3-4c75-8038-203fa1647546",
   "metadata": {},
   "source": [
    "### Create Model and Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8bc910e-8ce7-4b23-9b6e-b01e6b4b6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "loss_ = nn.MSELoss()\n",
    "n_input_features = X.shape[1]\n",
    "# Initialize architecture of our Auto-Encoder\n",
    "model = AutoEncoder(input_size=n_input_features, \n",
    "                    hidden_layers=[500, 500, 2000, \n",
    "                                 10 # This is the dimension of the embedding\n",
    "                                 ],\n",
    "                   # Prevent overfitting by deactivating 20% of the neurons during training\n",
    "                    dropout_rate=0.2 \n",
    "                   ).to(device) # use GPU if available\n",
    "\n",
    "# Activate training mode\n",
    "model.train()\n",
    "\n",
    "# We could restore a model to continue training from a checkpoint\n",
    "#model = torch.load(\"./torch_models/autoencoder\")\n",
    "\n",
    "# Learning Rate\n",
    "lr = 0.1\n",
    "\n",
    "# Use Stochastic Gradient Descent as optimizer with momentum 0.9\n",
    "optimizer = torch.optim.SGD(lr=lr, \n",
    "                            momentum=0.9,\n",
    "                            params=model.parameters())\n",
    "\n",
    "# reduce learning rate as training continues\n",
    "scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                  step_size=100,\n",
    "                                  gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f527de-bdb3-4524-a66f-3837ee03ed42",
   "metadata": {},
   "source": [
    "### Pre-train AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ce9d1e3-ffb1-4cf3-95dc-79a60586a70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [10 / 300]: 0.15367\n",
      "Loss at epoch [20 / 300]: 0.11907\n",
      "Loss at epoch [30 / 300]: 0.10583\n",
      "Loss at epoch [40 / 300]: 0.09897\n",
      "Loss at epoch [50 / 300]: 0.09449\n",
      "Loss at epoch [60 / 300]: 0.09127\n",
      "Loss at epoch [70 / 300]: 0.08858\n",
      "Loss at epoch [80 / 300]: 0.08652\n",
      "Loss at epoch [90 / 300]: 0.08475\n",
      "Loss at epoch [100 / 300]: 0.08328\n",
      "Loss at epoch [110 / 300]: 0.08255\n",
      "Loss at epoch [120 / 300]: 0.08241\n",
      "Loss at epoch [130 / 300]: 0.08223\n",
      "Loss at epoch [140 / 300]: 0.08211\n",
      "Loss at epoch [150 / 300]: 0.08204\n",
      "Loss at epoch [160 / 300]: 0.08185\n",
      "Loss at epoch [170 / 300]: 0.08171\n",
      "Loss at epoch [180 / 300]: 0.08164\n",
      "Loss at epoch [190 / 300]: 0.08155\n",
      "Loss at epoch [200 / 300]: 0.08138\n",
      "Loss at epoch [210 / 300]: 0.08127\n",
      "Loss at epoch [220 / 300]: 0.08128\n",
      "Loss at epoch [230 / 300]: 0.08131\n",
      "Loss at epoch [240 / 300]: 0.08133\n",
      "Loss at epoch [250 / 300]: 0.08127\n",
      "Loss at epoch [260 / 300]: 0.08122\n",
      "Loss at epoch [270 / 300]: 0.08124\n",
      "Loss at epoch [280 / 300]: 0.08119\n",
      "Loss at epoch [290 / 300]: 0.08123\n",
      "Loss at epoch [300 / 300]: 0.08114\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "eval_every = 10\n",
    "best_loss = np.infty\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    # Iterate over data in batches\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # PyTorch specific; We need to reset all gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 0. Transform input batch data from 28 X 28 to 784 features\n",
    "        #   Note that our encoder maps the data into just 10 features!\n",
    "        x_batch = x_batch.to(device)\n",
    "        x_batch = x_batch.view(x_batch.shape[0], -1)\n",
    "\n",
    "        # 1. Apply AutoEncoder model (forward pass).\n",
    "        #    We use the output of the decoder for training.\n",
    "        output = model(x_batch)[1]\n",
    "\n",
    "        # 2. Calculate the reconstruction loss        \n",
    "        loss = loss_(output, x_batch)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # 3. Backpropagate less\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    mean_loss = np.round(np.mean(losses),\n",
    "                         5)\n",
    "    if (epoch+1) % eval_every == 0:   \n",
    "        print(f\"Loss at epoch [{epoch+1} / {n_epochs}]: {mean_loss}\")\n",
    "    \n",
    "    # Update learning rate as training continues\n",
    "    scheduler.step()\n",
    "    \n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Store the model\n",
    "        torch.save(model, \"./torch_models/autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc91791-940b-4069-a2db-589e96e05e40",
   "metadata": {},
   "source": [
    "#### Fine-Tune Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97ef42c6-2d99-4f61-9479-f19fd8a121d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [10 / 100]: 0.04415\n",
      "Loss at epoch [20 / 100]: 0.0443\n",
      "Loss at epoch [30 / 100]: 0.04442\n",
      "Loss at epoch [40 / 100]: 0.0445\n",
      "Loss at epoch [50 / 100]: 0.04457\n",
      "Loss at epoch [60 / 100]: 0.04461\n",
      "Loss at epoch [70 / 100]: 0.04464\n",
      "Loss at epoch [80 / 100]: 0.04466\n",
      "Loss at epoch [90 / 100]: 0.04466\n",
      "Loss at epoch [100 / 100]: 0.04466\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = torch.load(\"./torch_models/autoencoder\")\n",
    "\n",
    "# Inference Mode for fine-tuning\n",
    "model.eval()\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(lr=lr, \n",
    "                            momentum=0.9,\n",
    "                            params=model.parameters()\n",
    "                           )\n",
    "n_epochs = 100\n",
    "eval_every = 10\n",
    "best_loss = np.infty\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # Reset gradients --> Specific for PyTorch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use GPU\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        # Image has shape 28 x 28 -> Transform to 784 features using flattening\n",
    "        x_batch = x_batch.view(x_batch.shape[0], -1)\n",
    "        \n",
    "        # Apply the model\n",
    "        output = model(x_batch)[1]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_(output, x_batch)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    mean_loss = np.round(np.mean(losses),5)\n",
    "    if (epoch+1) % eval_every == 0:   \n",
    "        print(f\"Loss at epoch [{epoch+1} / {n_epochs}]: {mean_loss}\")\n",
    "    torch.save(model, \"./torch_models/autoencoder-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ebe3a-a2e1-4061-83f6-2395d3c0ce25",
   "metadata": {},
   "source": [
    "## Baseline KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8a01566-2f34-4f60-a6d9-d8dd845dd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# Use the actual number of clusters as parameter\n",
    "n_clusters = len(np.unique(y))\n",
    "\n",
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Get training predictions\n",
    "y_pred_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2494d11c-0d06-4e7a-b4ab-4ef38f7180de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of k-Means Clustering:\n",
      "AMI: 0.5\n",
      "ARI: 0.367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "print(\"Accuracy of k-Means Clustering:\")\n",
    "ami_kmeans = adjusted_mutual_info_score(y, y_pred_kmeans)\n",
    "ari_kmeans = adjusted_rand_score(y, y_pred_kmeans)\n",
    "print(f\"AMI: {np.round(ami_kmeans, 3)}\")\n",
    "print(f\"ARI: {np.round(ari_kmeans, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccda24-a6c5-4566-9e4e-7c50a5db5d53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ece0847a-5cb2-496c-a582-f8e691baa724",
   "metadata": {},
   "source": [
    "## Apply Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5187531-7d26-4913-8d6b-ed89116c1deb",
   "metadata": {},
   "source": [
    "### Evaluate Pre-trained Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f66a0d65-513c-43e8-811f-4eb488c3b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./torch_models/autoencoder\")\n",
    "X_embedded_pretrained = model(Tensor(X).to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa1a7f4d-bc77-4724-8585-1da86f5af4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Convert Data to CPU and apply kmeans to get the cluster predictions\n",
    "y_pred_AE_pretrained = kmeans.fit_predict(X_embedded_pretrained.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a483888-3997-4ed1-a99c-4dc34953796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Auto-Encoder:\n",
      "AMI: 55.4\n",
      "ARI: 47.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Auto-Encoder:\")\n",
    "ami_AE_pretrained = adjusted_mutual_info_score(y, y_pred_AE_pretrained)\n",
    "ari_AE_pretrained = adjusted_rand_score(y, y_pred_AE_pretrained)\n",
    "print(f\"AMI: {np.round(ami_AE_pretrained * 100, 1)}\")\n",
    "print(f\"ARI: {np.round(ari_AE_pretrained * 100, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e14f2b-31e8-4726-8d94-554664f60911",
   "metadata": {},
   "source": [
    "### Evaluate Fine-tuned Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de956cdd-6e91-42ca-b327-8f1aa1f03d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./torch_models/autoencoder-finetuned-old\")\n",
    "X_embedded = model(Tensor(X).to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7f4a62e-ebd8-4048-a5e7-068d795f6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Get training predictions\n",
    "y_pred_AE_finetuned = kmeans.fit_predict(X_embedded.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0397e545-0621-4cad-b2fc-3698026cc48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Auto-Encoder:\n",
      "AMI: 72.8\n",
      "ARI: 66.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Auto-Encoder:\")\n",
    "ami_AE_finetuned = adjusted_mutual_info_score(y, y_pred_AE_finetuned)\n",
    "ari_AE_finetuned = adjusted_rand_score(y, y_pred_AE_finetuned)\n",
    "print(f\"AMI: {np.round(ami_AE_finetuned*100, 1)}\")\n",
    "print(f\"ARI: {np.round(ari_AE_finetuned*100, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c56f04-1748-4a8e-aafe-fb2cf34568e8",
   "metadata": {},
   "source": [
    "## Overall Evaluation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17e8a1e0-6b7c-4854-b673-3439ff485338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Clustering Approach\": [\"k-Means\", \"Auto-Encoder (pre-trained)\", \"Auto-Encoder (fine-tuned)\"],\n",
    "                   \"AMI\": [ami_kmeans, ami_AE_pretrained, ami_AE_finetuned],\n",
    "                  \"ARI\": [ari_kmeans, ari_AE_pretrained, ari_AE_finetuned]})\n",
    "df[\"AMI\"] *= 100\n",
    "df[\"ARI\"] *= 100\n",
    "df[\"AMI\"] = df[\"AMI\"].round(1)\n",
    "df[\"ARI\"] = df[\"ARI\"].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79f3119c-7579-45d4-b3e2-8bcf21d55c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering Approach</th>\n",
       "      <th>AMI</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-Means</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auto-Encoder (pre-trained)</td>\n",
       "      <td>55.4</td>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto-Encoder (fine-tuned)</td>\n",
       "      <td>72.8</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Clustering Approach   AMI   ARI\n",
       "0                     k-Means  50.0  36.7\n",
       "1  Auto-Encoder (pre-trained)  55.4  47.1\n",
       "2   Auto-Encoder (fine-tuned)  72.8  66.3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
