{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c43bbd-5d2f-45a7-9d6f-a9fc676b1e15",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf3c892-f899-40e5-a3f6-fb55bf37f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rs = 1234\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d4e73-6fc4-4585-b6c5-a4e2a9643b61",
   "metadata": {},
   "source": [
    "# Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace1d630-1d0a-4718-be08-7f0fe2205b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb74580-f713-4b62-ba27-452ce32d7614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should print type='cuda' if GPU is available, otherwise 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911c685-bff4-48f4-93fa-fa5afa20ce5e",
   "metadata": {},
   "source": [
    "## Defining the Auto-Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f57b9f-3d54-403f-ba2f-8f3744a787a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder network. \n",
    "    A deep neural network that learns a lower-dimensional representation of the input data by mapping it into an embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                hidden_sizes: Tuple[int],\n",
    "                 dropout_rate: float=0.2,\n",
    "                 activation=nn.ReLU()\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First layer, the input layer\n",
    "        self.input_layer = torch.nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.n_layers = 0\n",
    "\n",
    "        ######################################################\n",
    "        # Usually we could specify the layers in this way:\n",
    "        # self.dense_0 = torch.nn.Linear(input_size, hidden_sizes[0])\n",
    "        # self.dense_1 = torch.nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        # ....\n",
    "        # \n",
    "        # However, instead of hardcoding this, we can do it automatically based on the hidden_sizes\n",
    "        #######################################################\n",
    "        for i in range(0, len(hidden_sizes) -1):\n",
    "            setattr(self, f\"dense_{i}\", torch.nn.Linear(hidden_sizes[i],\n",
    "                                                        hidden_sizes[i+1])\n",
    "                   )\n",
    "            self.n_layers += 1\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        \n",
    "        # Add dropout to prevent overfitting\n",
    "        self.dropout  = nn.Dropout(dropout_rate)\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # Special Treatment for input layer\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        \n",
    "        #################################################\n",
    "        # forward pass through the dense layers\n",
    "        # We could have written each dense layer explicitly:\n",
    "        # x = self.activation(self.dense_0(x))\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.activation(self.dense_1(x))\n",
    "        # .....\n",
    "        # \n",
    "        # But we do it automatically:\n",
    "        ##################################################\n",
    "        for i in range(0, self.n_layers -1):\n",
    "            x = self.activation(getattr(self, f\"dense_{i}\")(x))\n",
    "            # dropout to prevent overfitting\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Use layer without activation function to output embedding\n",
    "        output_layer = getattr(self, f\"dense_{self.n_layers-1}\")\n",
    "        return output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9dedb01-4e68-425a-99b6-a486d3670a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Same as the encoder, but the layers are in reverse order. \n",
    "    So, we pass the encoder as input and use its hidden_sizes to specify the decoder network.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder,\n",
    "                 activation=nn.ReLU()\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.hidden_sizes = encoder.hidden_sizes\n",
    "        n_layers = encoder.n_layers\n",
    "        self.hidden_sizes = self.hidden_sizes[::-1]\n",
    "        \n",
    "        # Reversed order -> dense_0 will be the first to apply here\n",
    "        for i in range(0, n_layers):\n",
    "            setattr(self, f\"dense_{i}\", torch.nn.Linear(self.hidden_sizes[i],\n",
    "                                                        self.hidden_sizes[i+1])\n",
    "                   )\n",
    "        self.output_layer = torch.nn.Linear(self.hidden_sizes[-1],\n",
    "                                                        encoder.input_size)\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "        self.dropout  = nn.Dropout(encoder.dropout_rate)\n",
    "\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        for i in range(0, self.n_layers):\n",
    "            dense_i = getattr(self, f\"dense_{i}\")\n",
    "            x = dense_i(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03bc9e67-81b1-42a5-9aa4-181b3eb5e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete AutoEncoder that consists of the encoder and the decoder network. \n",
    "    We need this for training, but for applying the autoencoder, we will only need the encoder to map input data to an embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                hidden_sizes: Tuple[int],\n",
    "                 dropout_rate: float=0.2,\n",
    "                activation=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_sizes, dropout_rate)\n",
    "        self.decoder = Decoder(self.encoder)\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor]:\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96218cd6-3757-4c7b-a5b4-bbfa306e4347",
   "metadata": {},
   "source": [
    "### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd5ab1a3-eb94-44e4-b941-37a4d0efe89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = MNIST('./', download=True,\n",
    "                 train=True,\n",
    "                 transform=transform)\n",
    "testset = MNIST('./', download=True,\n",
    "                 train=False,\n",
    "                 transform=transform)\n",
    "dataset = ConcatDataset([trainset, testset])\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=256, \n",
    "                                         shuffle=True,\n",
    "                                         num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04b913a-ae78-46c0-95b3-6ed4fc451e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = trainset.data.numpy().reshape(60000, 784)\n",
    "X_test = testset.data.numpy().reshape(10000, 784)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d54bb60-0502-404b-855e-124bb3b115ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(trainset.targets)\n",
    "y_test = np.array(testset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e088416a-a7f7-4c8b-abd3-c09138017a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.concatenate([y_train, y_test])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62a55a-f9b3-4c75-8038-203fa1647546",
   "metadata": {},
   "source": [
    "### Create Model and Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bc910e-8ce7-4b23-9b6e-b01e6b4b6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "loss_ = nn.MSELoss()\n",
    "n_input_features = X.shape[1]\n",
    "# Initialize architecture of our Auto-Encoder\n",
    "model = AutoEncoder(input_size=n_input_features, \n",
    "                    hidden_sizes=[500, 500, 2000, \n",
    "                                 10 # This is the dimension of the embedding\n",
    "                                 ],\n",
    "                   # Prevent overfitting by deactivating 20% of the neurons during training\n",
    "                    dropout_rate=0.2 \n",
    "                   ).to(device) # use GPU if available\n",
    "\n",
    "# Activate training mode\n",
    "model.train()\n",
    "\n",
    "# We could restore a model to continue training from a checkpoint\n",
    "#model = torch.load(\"./torch_models/autoencoder\")\n",
    "\n",
    "# Learning Rate\n",
    "lr = 0.1\n",
    "\n",
    "# Use Stochastic Gradient Descent as optimizer with momentum 0.9\n",
    "optimizer = torch.optim.SGD(lr=lr, \n",
    "                            momentum=0.9,\n",
    "                            params=model.parameters())\n",
    "\n",
    "# reduce learning rate as training continues\n",
    "scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                  step_size=100,\n",
    "                                  gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f527de-bdb3-4524-a66f-3837ee03ed42",
   "metadata": {},
   "source": [
    "### Pre-train AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ce9d1e3-ffb1-4cf3-95dc-79a60586a70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [10 / 300]: 0.15144\n",
      "Loss at epoch [20 / 300]: 0.11768\n",
      "Loss at epoch [30 / 300]: 0.10562\n",
      "Loss at epoch [40 / 300]: 0.09888\n",
      "Loss at epoch [50 / 300]: 0.09435\n",
      "Loss at epoch [60 / 300]: 0.09095\n",
      "Loss at epoch [70 / 300]: 0.08822\n",
      "Loss at epoch [80 / 300]: 0.08609\n",
      "Loss at epoch [90 / 300]: 0.08431\n",
      "Loss at epoch [100 / 300]: 0.08283\n",
      "Loss at epoch [110 / 300]: 0.08216\n",
      "Loss at epoch [120 / 300]: 0.08196\n",
      "Loss at epoch [130 / 300]: 0.08188\n",
      "Loss at epoch [140 / 300]: 0.08165\n",
      "Loss at epoch [150 / 300]: 0.08155\n",
      "Loss at epoch [160 / 300]: 0.08142\n",
      "Loss at epoch [170 / 300]: 0.08128\n",
      "Loss at epoch [180 / 300]: 0.08116\n",
      "Loss at epoch [190 / 300]: 0.08103\n",
      "Loss at epoch [200 / 300]: 0.08083\n",
      "Loss at epoch [210 / 300]: 0.08084\n",
      "Loss at epoch [220 / 300]: 0.08085\n",
      "Loss at epoch [230 / 300]: 0.08083\n",
      "Loss at epoch [240 / 300]: 0.0808\n",
      "Loss at epoch [250 / 300]: 0.08074\n",
      "Loss at epoch [260 / 300]: 0.0807\n",
      "Loss at epoch [270 / 300]: 0.0808\n",
      "Loss at epoch [280 / 300]: 0.08078\n",
      "Loss at epoch [290 / 300]: 0.08073\n",
      "Loss at epoch [300 / 300]: 0.08066\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "eval_every = 10\n",
    "best_loss = np.infty\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    # Iterate over data in batches\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # Transform input batch data\n",
    "        x_batch = x_batch.to(device)\n",
    "        x_batch = x_batch.view(x_batch.shape[0], -1)\n",
    "\n",
    "        # Apply AutoEncoder model\n",
    "        output = model(x_batch)[1]\n",
    "\n",
    "        # Calculate the reconstruction loss\n",
    "        loss = loss_(output, x_batch)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    mean_loss = np.round(np.mean(losses),\n",
    "                         5)\n",
    "    if (epoch+1) % eval_every == 0:   \n",
    "        print(f\"Loss at epoch [{epoch+1} / {n_epochs}]: {mean_loss}\")\n",
    "\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = loss\n",
    "        # Store the model\n",
    "        torch.save(model, \"./torch_models/autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc91791-940b-4069-a2db-589e96e05e40",
   "metadata": {},
   "source": [
    "#### Fine-Tune Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ef42c6-2d99-4f61-9479-f19fd8a121d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [1 / 300]: 0.07079\n",
      "Loss at epoch [2 / 300]: 0.06713\n",
      "Loss at epoch [3 / 300]: 0.06512\n",
      "Loss at epoch [4 / 300]: 0.0638\n",
      "Loss at epoch [5 / 300]: 0.06284\n",
      "Loss at epoch [6 / 300]: 0.06208\n",
      "Loss at epoch [7 / 300]: 0.06146\n",
      "Loss at epoch [8 / 300]: 0.06093\n",
      "Loss at epoch [9 / 300]: 0.06046\n",
      "Loss at epoch [10 / 300]: 0.06005\n",
      "Loss at epoch [11 / 300]: 0.05968\n",
      "Loss at epoch [12 / 300]: 0.05934\n",
      "Loss at epoch [13 / 300]: 0.05903\n",
      "Loss at epoch [14 / 300]: 0.05874\n",
      "Loss at epoch [15 / 300]: 0.05846\n",
      "Loss at epoch [16 / 300]: 0.0582\n",
      "Loss at epoch [17 / 300]: 0.05796\n",
      "Loss at epoch [18 / 300]: 0.05773\n",
      "Loss at epoch [19 / 300]: 0.0575\n",
      "Loss at epoch [20 / 300]: 0.05729\n",
      "Loss at epoch [21 / 300]: 0.05708\n",
      "Loss at epoch [22 / 300]: 0.05689\n",
      "Loss at epoch [23 / 300]: 0.0567\n",
      "Loss at epoch [24 / 300]: 0.05651\n",
      "Loss at epoch [25 / 300]: 0.05634\n",
      "Loss at epoch [26 / 300]: 0.05616\n",
      "Loss at epoch [27 / 300]: 0.056\n",
      "Loss at epoch [28 / 300]: 0.05583\n",
      "Loss at epoch [29 / 300]: 0.05568\n",
      "Loss at epoch [30 / 300]: 0.05552\n",
      "Loss at epoch [31 / 300]: 0.05537\n",
      "Loss at epoch [32 / 300]: 0.05522\n",
      "Loss at epoch [33 / 300]: 0.05508\n",
      "Loss at epoch [34 / 300]: 0.05494\n",
      "Loss at epoch [35 / 300]: 0.0548\n",
      "Loss at epoch [36 / 300]: 0.05467\n",
      "Loss at epoch [37 / 300]: 0.05454\n",
      "Loss at epoch [38 / 300]: 0.05441\n",
      "Loss at epoch [39 / 300]: 0.05428\n",
      "Loss at epoch [40 / 300]: 0.05416\n",
      "Loss at epoch [41 / 300]: 0.05404\n",
      "Loss at epoch [42 / 300]: 0.05392\n",
      "Loss at epoch [43 / 300]: 0.0538\n",
      "Loss at epoch [44 / 300]: 0.05368\n",
      "Loss at epoch [45 / 300]: 0.05357\n",
      "Loss at epoch [46 / 300]: 0.05346\n",
      "Loss at epoch [47 / 300]: 0.05335\n",
      "Loss at epoch [48 / 300]: 0.05324\n",
      "Loss at epoch [49 / 300]: 0.05314\n",
      "Loss at epoch [50 / 300]: 0.05303\n",
      "Loss at epoch [51 / 300]: 0.05293\n",
      "Loss at epoch [52 / 300]: 0.05283\n",
      "Loss at epoch [53 / 300]: 0.05273\n",
      "Loss at epoch [54 / 300]: 0.05263\n",
      "Loss at epoch [55 / 300]: 0.05253\n",
      "Loss at epoch [56 / 300]: 0.05244\n",
      "Loss at epoch [57 / 300]: 0.05234\n",
      "Loss at epoch [58 / 300]: 0.05225\n",
      "Loss at epoch [59 / 300]: 0.05216\n",
      "Loss at epoch [60 / 300]: 0.05207\n",
      "Loss at epoch [61 / 300]: 0.05198\n",
      "Loss at epoch [62 / 300]: 0.05189\n",
      "Loss at epoch [63 / 300]: 0.0518\n",
      "Loss at epoch [64 / 300]: 0.05172\n",
      "Loss at epoch [65 / 300]: 0.05163\n",
      "Loss at epoch [66 / 300]: 0.05155\n",
      "Loss at epoch [67 / 300]: 0.05147\n",
      "Loss at epoch [68 / 300]: 0.05138\n",
      "Loss at epoch [69 / 300]: 0.0513\n",
      "Loss at epoch [70 / 300]: 0.05122\n",
      "Loss at epoch [71 / 300]: 0.05114\n",
      "Loss at epoch [72 / 300]: 0.05107\n",
      "Loss at epoch [73 / 300]: 0.05099\n",
      "Loss at epoch [74 / 300]: 0.05091\n",
      "Loss at epoch [75 / 300]: 0.05084\n",
      "Loss at epoch [76 / 300]: 0.05076\n",
      "Loss at epoch [77 / 300]: 0.05069\n",
      "Loss at epoch [78 / 300]: 0.05062\n",
      "Loss at epoch [79 / 300]: 0.05054\n",
      "Loss at epoch [80 / 300]: 0.05047\n",
      "Loss at epoch [81 / 300]: 0.0504\n",
      "Loss at epoch [82 / 300]: 0.05033\n",
      "Loss at epoch [83 / 300]: 0.05026\n",
      "Loss at epoch [84 / 300]: 0.05019\n",
      "Loss at epoch [85 / 300]: 0.05013\n",
      "Loss at epoch [86 / 300]: 0.05006\n",
      "Loss at epoch [87 / 300]: 0.04999\n",
      "Loss at epoch [88 / 300]: 0.04993\n",
      "Loss at epoch [89 / 300]: 0.04986\n",
      "Loss at epoch [90 / 300]: 0.0498\n",
      "Loss at epoch [91 / 300]: 0.04973\n",
      "Loss at epoch [92 / 300]: 0.04967\n",
      "Loss at epoch [93 / 300]: 0.04961\n",
      "Loss at epoch [94 / 300]: 0.04954\n",
      "Loss at epoch [95 / 300]: 0.04948\n",
      "Loss at epoch [96 / 300]: 0.04942\n",
      "Loss at epoch [97 / 300]: 0.04936\n",
      "Loss at epoch [98 / 300]: 0.0493\n",
      "Loss at epoch [99 / 300]: 0.04924\n",
      "Loss at epoch [100 / 300]: 0.04918\n",
      "Loss at epoch [101 / 300]: 0.04912\n",
      "Loss at epoch [102 / 300]: 0.04907\n",
      "Loss at epoch [103 / 300]: 0.04901\n",
      "Loss at epoch [104 / 300]: 0.04895\n",
      "Loss at epoch [105 / 300]: 0.04889\n",
      "Loss at epoch [106 / 300]: 0.04884\n",
      "Loss at epoch [107 / 300]: 0.04878\n",
      "Loss at epoch [108 / 300]: 0.04873\n",
      "Loss at epoch [109 / 300]: 0.04867\n",
      "Loss at epoch [110 / 300]: 0.04862\n",
      "Loss at epoch [111 / 300]: 0.04857\n",
      "Loss at epoch [112 / 300]: 0.04851\n",
      "Loss at epoch [113 / 300]: 0.04846\n",
      "Loss at epoch [114 / 300]: 0.04841\n",
      "Loss at epoch [115 / 300]: 0.04835\n",
      "Loss at epoch [116 / 300]: 0.0483\n",
      "Loss at epoch [117 / 300]: 0.04825\n",
      "Loss at epoch [118 / 300]: 0.0482\n",
      "Loss at epoch [119 / 300]: 0.04815\n",
      "Loss at epoch [120 / 300]: 0.0481\n",
      "Loss at epoch [121 / 300]: 0.04805\n",
      "Loss at epoch [122 / 300]: 0.048\n",
      "Loss at epoch [123 / 300]: 0.04795\n",
      "Loss at epoch [124 / 300]: 0.0479\n",
      "Loss at epoch [125 / 300]: 0.04785\n",
      "Loss at epoch [126 / 300]: 0.04781\n",
      "Loss at epoch [127 / 300]: 0.04776\n",
      "Loss at epoch [128 / 300]: 0.04771\n",
      "Loss at epoch [129 / 300]: 0.04767\n",
      "Loss at epoch [130 / 300]: 0.04762\n",
      "Loss at epoch [131 / 300]: 0.04757\n",
      "Loss at epoch [132 / 300]: 0.04753\n",
      "Loss at epoch [133 / 300]: 0.04748\n",
      "Loss at epoch [134 / 300]: 0.04744\n",
      "Loss at epoch [135 / 300]: 0.04739\n",
      "Loss at epoch [136 / 300]: 0.04735\n",
      "Loss at epoch [137 / 300]: 0.0473\n",
      "Loss at epoch [138 / 300]: 0.04726\n",
      "Loss at epoch [139 / 300]: 0.04721\n",
      "Loss at epoch [140 / 300]: 0.04717\n",
      "Loss at epoch [141 / 300]: 0.04713\n",
      "Loss at epoch [142 / 300]: 0.04708\n",
      "Loss at epoch [143 / 300]: 0.04704\n",
      "Loss at epoch [144 / 300]: 0.047\n",
      "Loss at epoch [145 / 300]: 0.04696\n",
      "Loss at epoch [146 / 300]: 0.04691\n",
      "Loss at epoch [147 / 300]: 0.04687\n",
      "Loss at epoch [148 / 300]: 0.04683\n",
      "Loss at epoch [149 / 300]: 0.04679\n",
      "Loss at epoch [150 / 300]: 0.04675\n",
      "Loss at epoch [151 / 300]: 0.04671\n",
      "Loss at epoch [152 / 300]: 0.04667\n",
      "Loss at epoch [153 / 300]: 0.04663\n",
      "Loss at epoch [154 / 300]: 0.04659\n",
      "Loss at epoch [155 / 300]: 0.04655\n",
      "Loss at epoch [156 / 300]: 0.04651\n",
      "Loss at epoch [157 / 300]: 0.04647\n",
      "Loss at epoch [158 / 300]: 0.04643\n",
      "Loss at epoch [159 / 300]: 0.04639\n",
      "Loss at epoch [160 / 300]: 0.04635\n",
      "Loss at epoch [161 / 300]: 0.04632\n",
      "Loss at epoch [162 / 300]: 0.04628\n",
      "Loss at epoch [163 / 300]: 0.04624\n",
      "Loss at epoch [164 / 300]: 0.0462\n",
      "Loss at epoch [165 / 300]: 0.04617\n",
      "Loss at epoch [166 / 300]: 0.04613\n",
      "Loss at epoch [167 / 300]: 0.04609\n",
      "Loss at epoch [168 / 300]: 0.04606\n",
      "Loss at epoch [169 / 300]: 0.04602\n",
      "Loss at epoch [170 / 300]: 0.04598\n",
      "Loss at epoch [171 / 300]: 0.04595\n",
      "Loss at epoch [172 / 300]: 0.04591\n",
      "Loss at epoch [173 / 300]: 0.04588\n",
      "Loss at epoch [174 / 300]: 0.04584\n",
      "Loss at epoch [175 / 300]: 0.0458\n",
      "Loss at epoch [176 / 300]: 0.04577\n",
      "Loss at epoch [177 / 300]: 0.04573\n",
      "Loss at epoch [178 / 300]: 0.0457\n",
      "Loss at epoch [179 / 300]: 0.04566\n",
      "Loss at epoch [180 / 300]: 0.04563\n",
      "Loss at epoch [181 / 300]: 0.0456\n",
      "Loss at epoch [182 / 300]: 0.04556\n",
      "Loss at epoch [183 / 300]: 0.04553\n",
      "Loss at epoch [184 / 300]: 0.0455\n",
      "Loss at epoch [185 / 300]: 0.04546\n",
      "Loss at epoch [186 / 300]: 0.04543\n",
      "Loss at epoch [187 / 300]: 0.0454\n",
      "Loss at epoch [188 / 300]: 0.04536\n",
      "Loss at epoch [189 / 300]: 0.04533\n",
      "Loss at epoch [190 / 300]: 0.0453\n",
      "Loss at epoch [191 / 300]: 0.04526\n",
      "Loss at epoch [192 / 300]: 0.04523\n",
      "Loss at epoch [193 / 300]: 0.0452\n",
      "Loss at epoch [194 / 300]: 0.04517\n",
      "Loss at epoch [195 / 300]: 0.04514\n",
      "Loss at epoch [196 / 300]: 0.0451\n",
      "Loss at epoch [197 / 300]: 0.04507\n",
      "Loss at epoch [198 / 300]: 0.04504\n",
      "Loss at epoch [199 / 300]: 0.04501\n",
      "Loss at epoch [200 / 300]: 0.04498\n",
      "Loss at epoch [201 / 300]: 0.04495\n",
      "Loss at epoch [202 / 300]: 0.04492\n",
      "Loss at epoch [203 / 300]: 0.04489\n",
      "Loss at epoch [204 / 300]: 0.04486\n",
      "Loss at epoch [205 / 300]: 0.04483\n",
      "Loss at epoch [206 / 300]: 0.0448\n",
      "Loss at epoch [207 / 300]: 0.04477\n",
      "Loss at epoch [208 / 300]: 0.04474\n",
      "Loss at epoch [209 / 300]: 0.04471\n",
      "Loss at epoch [210 / 300]: 0.04468\n",
      "Loss at epoch [211 / 300]: 0.04465\n",
      "Loss at epoch [212 / 300]: 0.04462\n",
      "Loss at epoch [213 / 300]: 0.04459\n",
      "Loss at epoch [214 / 300]: 0.04456\n",
      "Loss at epoch [215 / 300]: 0.04453\n",
      "Loss at epoch [216 / 300]: 0.0445\n",
      "Loss at epoch [217 / 300]: 0.04447\n",
      "Loss at epoch [218 / 300]: 0.04445\n",
      "Loss at epoch [219 / 300]: 0.04442\n",
      "Loss at epoch [220 / 300]: 0.04439\n",
      "Loss at epoch [221 / 300]: 0.04436\n",
      "Loss at epoch [222 / 300]: 0.04433\n",
      "Loss at epoch [223 / 300]: 0.0443\n",
      "Loss at epoch [224 / 300]: 0.04428\n",
      "Loss at epoch [225 / 300]: 0.04425\n",
      "Loss at epoch [226 / 300]: 0.04422\n",
      "Loss at epoch [227 / 300]: 0.04419\n",
      "Loss at epoch [228 / 300]: 0.04417\n",
      "Loss at epoch [229 / 300]: 0.04414\n",
      "Loss at epoch [230 / 300]: 0.04411\n",
      "Loss at epoch [231 / 300]: 0.04409\n",
      "Loss at epoch [232 / 300]: 0.04406\n",
      "Loss at epoch [233 / 300]: 0.04403\n",
      "Loss at epoch [234 / 300]: 0.04401\n",
      "Loss at epoch [235 / 300]: 0.04398\n",
      "Loss at epoch [236 / 300]: 0.04395\n",
      "Loss at epoch [237 / 300]: 0.04393\n",
      "Loss at epoch [238 / 300]: 0.0439\n",
      "Loss at epoch [239 / 300]: 0.04387\n",
      "Loss at epoch [240 / 300]: 0.04385\n",
      "Loss at epoch [241 / 300]: 0.04382\n",
      "Loss at epoch [242 / 300]: 0.0438\n",
      "Loss at epoch [243 / 300]: 0.04377\n",
      "Loss at epoch [244 / 300]: 0.04374\n",
      "Loss at epoch [245 / 300]: 0.04372\n",
      "Loss at epoch [246 / 300]: 0.04369\n",
      "Loss at epoch [247 / 300]: 0.04367\n",
      "Loss at epoch [248 / 300]: 0.04364\n",
      "Loss at epoch [249 / 300]: 0.04362\n",
      "Loss at epoch [250 / 300]: 0.04359\n",
      "Loss at epoch [251 / 300]: 0.04357\n",
      "Loss at epoch [252 / 300]: 0.04354\n",
      "Loss at epoch [253 / 300]: 0.04352\n",
      "Loss at epoch [254 / 300]: 0.04349\n",
      "Loss at epoch [255 / 300]: 0.04347\n",
      "Loss at epoch [256 / 300]: 0.04345\n",
      "Loss at epoch [257 / 300]: 0.04342\n",
      "Loss at epoch [258 / 300]: 0.0434\n",
      "Loss at epoch [259 / 300]: 0.04337\n",
      "Loss at epoch [260 / 300]: 0.04335\n",
      "Loss at epoch [261 / 300]: 0.04333\n",
      "Loss at epoch [262 / 300]: 0.0433\n",
      "Loss at epoch [263 / 300]: 0.04328\n",
      "Loss at epoch [264 / 300]: 0.04325\n",
      "Loss at epoch [265 / 300]: 0.04323\n",
      "Loss at epoch [266 / 300]: 0.04321\n",
      "Loss at epoch [267 / 300]: 0.04318\n",
      "Loss at epoch [268 / 300]: 0.04316\n",
      "Loss at epoch [269 / 300]: 0.04314\n",
      "Loss at epoch [270 / 300]: 0.04311\n",
      "Loss at epoch [271 / 300]: 0.04309\n",
      "Loss at epoch [272 / 300]: 0.04307\n",
      "Loss at epoch [273 / 300]: 0.04304\n",
      "Loss at epoch [274 / 300]: 0.04302\n",
      "Loss at epoch [275 / 300]: 0.043\n",
      "Loss at epoch [276 / 300]: 0.04298\n",
      "Loss at epoch [277 / 300]: 0.04295\n",
      "Loss at epoch [278 / 300]: 0.04293\n",
      "Loss at epoch [279 / 300]: 0.04291\n",
      "Loss at epoch [280 / 300]: 0.04289\n",
      "Loss at epoch [281 / 300]: 0.04286\n",
      "Loss at epoch [282 / 300]: 0.04284\n",
      "Loss at epoch [283 / 300]: 0.04282\n",
      "Loss at epoch [284 / 300]: 0.0428\n",
      "Loss at epoch [285 / 300]: 0.04278\n",
      "Loss at epoch [286 / 300]: 0.04275\n",
      "Loss at epoch [287 / 300]: 0.04273\n",
      "Loss at epoch [288 / 300]: 0.04271\n",
      "Loss at epoch [289 / 300]: 0.04269\n",
      "Loss at epoch [290 / 300]: 0.04267\n",
      "Loss at epoch [291 / 300]: 0.04265\n",
      "Loss at epoch [292 / 300]: 0.04262\n",
      "Loss at epoch [293 / 300]: 0.0426\n",
      "Loss at epoch [294 / 300]: 0.04258\n",
      "Loss at epoch [295 / 300]: 0.04256\n",
      "Loss at epoch [296 / 300]: 0.04254\n",
      "Loss at epoch [297 / 300]: 0.04252\n",
      "Loss at epoch [298 / 300]: 0.0425\n",
      "Loss at epoch [299 / 300]: 0.04248\n",
      "Loss at epoch [300 / 300]: 0.04245\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = torch.load(\"./torch_models/autoencoder\")\n",
    "\n",
    "# Inference Mode for fine-tuning\n",
    "model.eval()\n",
    "\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.SGD(lr=lr, \n",
    "                            momentum=0.9,\n",
    "                            params=model.parameters()\n",
    "                           )\n",
    "n_epochs = 300\n",
    "eval_every = 10\n",
    "best_loss = np.infty\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in dataloader:\n",
    "        # Use GPU\n",
    "        x_batch = x_batch.to(device)\n",
    "        \n",
    "        # Image has shape 28 x 28 -> Transform to 784 features\n",
    "        x_batch = x_batch.view(x_batch.shape[0], -1)\n",
    "        \n",
    "        # Apply the model\n",
    "        output = model(x_batch)[1]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_(output, x_batch)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Reset gradients --> Specific for PyTorch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    mean_loss = np.round(np.mean(losses),5)\n",
    "    if (epoch+1) % eval_every == 0:   \n",
    "        print(f\"Loss at epoch [{epoch+1} / {n_epochs}]: {mean_loss}\")\n",
    "    torch.save(model, \"./torch_models/autoencoder-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ebe3a-a2e1-4061-83f6-2395d3c0ce25",
   "metadata": {},
   "source": [
    "## Baseline KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a01566-2f34-4f60-a6d9-d8dd845dd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "# Use the actual number of clusters as parameter\n",
    "n_clusters = len(np.unique(y))\n",
    "\n",
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Get training predictions\n",
    "y_pred_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2494d11c-0d06-4e7a-b4ab-4ef38f7180de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of k-Means Clustering:\n",
      "AMI: 0.5\n",
      "ARI: 0.367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "print(\"Accuracy of k-Means Clustering:\")\n",
    "ami_kmeans = adjusted_mutual_info_score(y, y_pred_kmeans)\n",
    "ari_kmeans = adjusted_rand_score(y, y_pred_kmeans)\n",
    "print(f\"AMI: {np.round(ami_kmeans, 3)}\")\n",
    "print(f\"ARI: {np.round(ari_kmeans, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0847a-5cb2-496c-a582-f8e691baa724",
   "metadata": {},
   "source": [
    "## Apply Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5187531-7d26-4913-8d6b-ed89116c1deb",
   "metadata": {},
   "source": [
    "### Evaluate Pre-trained Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f66a0d65-513c-43e8-811f-4eb488c3b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./torch_models/autoencoder\")\n",
    "X_embedded_pretrained = model(Tensor(X).to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa1a7f4d-bc77-4724-8585-1da86f5af4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Convert Data to CPU and apply kmeans to get the cluster predictions\n",
    "y_pred_AE_pretrained = kmeans.fit_predict(X_embedded_pretrained.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a483888-3997-4ed1-a99c-4dc34953796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Auto-Encoder:\n",
      "AMI: 55.2\n",
      "ARI: 47.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Auto-Encoder:\")\n",
    "ami_AE_pretrained = adjusted_mutual_info_score(y, y_pred_AE_pretrained)\n",
    "ari_AE_pretrained = adjusted_rand_score(y, y_pred_AE_pretrained)\n",
    "print(f\"AMI: {np.round(ami_AE_pretrained * 100, 1)}\")\n",
    "print(f\"ARI: {np.round(ari_AE_pretrained * 100, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e14f2b-31e8-4726-8d94-554664f60911",
   "metadata": {},
   "source": [
    "### Evaluate Fine-tuned Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de956cdd-6e91-42ca-b327-8f1aa1f03d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./torch_models/autoencoder-finetuned\")\n",
    "X_embedded = model(Tensor(X).to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7f4a62e-ebd8-4048-a5e7-068d795f6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kmeans using sklearn\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=rs)\n",
    "\n",
    "# Get training predictions\n",
    "y_pred_AE_finetuned = kmeans.fit_predict(X_embedded.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0397e545-0621-4cad-b2fc-3698026cc48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Auto-Encoder:\n",
      "AMI: 70.7\n",
      "ARI: 63.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Auto-Encoder:\")\n",
    "ami_AE_finetuned = adjusted_mutual_info_score(y, y_pred_AE_finetuned)\n",
    "ari_AE_finetuned = adjusted_rand_score(y, y_pred_AE_finetuned)\n",
    "print(f\"AMI: {np.round(ami_AE_finetuned*100, 1)}\")\n",
    "print(f\"ARI: {np.round(ari_AE_finetuned*100, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c56f04-1748-4a8e-aafe-fb2cf34568e8",
   "metadata": {},
   "source": [
    "## Overall Evaluation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17e8a1e0-6b7c-4854-b673-3439ff485338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Clustering Approach\": [\"k-Means\", \"Auto-Encoder (pre-trained)\", \"Auto-Encoder (fine-tuned)\"],\n",
    "                   \"AMI\": [ami_kmeans, ami_AE_pretrained, ami_AE_finetuned],\n",
    "                  \"ARI\": [ari_kmeans, ari_AE_pretrained, ari_AE_finetuned]})\n",
    "df[\"AMI\"] *= 100\n",
    "df[\"ARI\"] *= 100\n",
    "df[\"AMI\"] = df[\"AMI\"].round(1)\n",
    "df[\"ARI\"] = df[\"ARI\"].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79f3119c-7579-45d4-b3e2-8bcf21d55c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering Approach</th>\n",
       "      <th>AMI</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-Means</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Auto-Encoder (pre-trained)</td>\n",
       "      <td>55.2</td>\n",
       "      <td>47.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Auto-Encoder (fine-tuned)</td>\n",
       "      <td>70.7</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Clustering Approach   AMI   ARI\n",
       "0                     k-Means  50.0  36.7\n",
       "1  Auto-Encoder (pre-trained)  55.2  47.2\n",
       "2   Auto-Encoder (fine-tuned)  70.7  63.6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ca9cd-e95e-490a-aea5-7001c132dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for Auto-Encoder:\")\n",
    "print(f\"AMI: {adjusted_mutual_info_score(y, y_pred_train_AE)}\")\n",
    "print(f\"ARI: {adjusted_rand_score(y, y_pred_train_AE)}\")\n",
    "print(f\"Accuracy: {clustering_accuracy(y, y_pred_train_AE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fecf86-9f55-4c6c-9b06-57907607e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_cluster_centers = model.decoder(Tensor(kmeans.cluster_centers_).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ead75-8e5b-4942-9476-8e8d3d083b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, n_clusters)\n",
    "n_clusters = len(decoded_cluster_centers)\n",
    "\n",
    "for c_i in range(n_clusters):\n",
    "\n",
    "    # get center for cluster c_i and reshape it for plotting\n",
    "    image = decoded_cluster_centers[c_i].reshape(28,28)\n",
    "\n",
    "    # plot the cluster centers\n",
    "    axes[c_i].imshow(image.detach().cpu(), \n",
    "              cmap='grey')\n",
    "\n",
    "    # Styling: Turn off x/y ticks\n",
    "    axes[c_i].set_yticks([])\n",
    "    axes[c_i].set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779f622-01dc-4390-bbd5-e4bb8b9c71e9",
   "metadata": {},
   "source": [
    "Using Auto-Encoders, we are able to increase the accuracy of the simple k-Means clustering algorithm by more than 20%-points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7a664-925d-4e15-be2a-b40afd099738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_viz = TSNE(n_components=2, n_iter=1000).fit_transform(X_train_embedded.detach().cpu()[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd7a2e-d388-4455-bea0-21fc077bc42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_viz = KMeans(n_clusters=10)\n",
    "y_viz = kmeans_viz.fit_predict(X_viz)\n",
    "ax = plt.scatter(X_viz[0:1000, 0],\n",
    "                 X_viz[0:1000, 1], \n",
    "                 c=y_viz[0:1000])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eda95b-2fc9-4207-87ae-e9e5f7eb34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.scatter(X_viz[0:1000, 0], X_viz[0:1000, 1], c=\"grey\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
